{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distrib_zoo as dz\n",
    "import torch\n",
    "from layers import *\n",
    "from func import *\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glow = Glow(3, 6, 8, 4, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([3,3])\n",
    "cond = torch.rand([7,6])\n",
    "seg_ids = [2,2,3]\n",
    "x.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_F = SimpleLinear(\n",
    "    8,\n",
    "    8,\n",
    "    2\n",
    ")\n",
    "affine_G = SimpleLinear(\n",
    "    7,\n",
    "    8,\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice = Nice(affine_F, affine_G, [1,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0597, 0.4525, 1.8302],\n",
       "         [0.9363, 0.5432, 0.6319],\n",
       "         [1.5743, 1.0123, 1.0401]], grad_fn=<CatBackward>),\n",
       " tensor([ 0.2147, -0.1073, -0.0350], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice.likelihood(x, cond, seg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.5157, 5.9833, 6.2127], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glow.likelihood(x, cond, seg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([7,4])\n",
    "b = torch.rand([7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0964, 0.2835, 0.3648, 0.0796],\n",
       "        [0.9032, 0.4627, 0.6628, 0.8152],\n",
       "        [0.4207, 0.7454, 0.4469, 0.7976]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a[:3]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0964, 0.2835, 0.3648, 0.0796],\n",
       "        [0.0964, 0.2835, 0.3648, 0.0796],\n",
       "        [0.9032, 0.4627, 0.6628, 0.8152],\n",
       "        [0.9032, 0.4627, 0.6628, 0.8152],\n",
       "        [0.9032, 0.4627, 0.6628, 0.8152],\n",
       "        [0.4207, 0.7454, 0.4469, 0.7976],\n",
       "        [0.4207, 0.7454, 0.4469, 0.7976],\n",
       "        [0.4207, 0.7454, 0.4469, 0.7976]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(a, torch.tensor([2,3,3]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "repeat(*sizes) -> Tensor\n",
       "\n",
       "Repeats this tensor along the specified dimensions.\n",
       "\n",
       "Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "    :func:`torch.repeat` behaves differently from\n",
       "    `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
       "    but is more similar to\n",
       "    `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
       "    For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
       "\n",
       "Args:\n",
       "    sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
       "        dimension\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> x = torch.tensor([1, 2, 3])\n",
       "    >>> x.repeat(4, 2)\n",
       "    tensor([[ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3],\n",
       "            [ 1,  2,  3,  1,  2,  3]])\n",
       "    >>> x.repeat(4, 2, 1).size()\n",
       "    torch.Size([4, 2, 3])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?a.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]), tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]), tensor([[1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a, a.size(1) // 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
       "\n",
       "Shape:\n",
       "\n",
       "    - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
       "      additional dimensions\n",
       "    - Weight: :math:`(out\\_features, in\\_features)`\n",
       "    - Bias: :math:`(out\\_features)`\n",
       "    - Output: :math:`(N, *, out\\_features)`\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?F.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dz.InvLinear(7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023],\n",
       "        [-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023],\n",
       "        [-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1820, 4.1477, 2.7423, 3.8388, 3.6860],\n",
       "        [3.1820, 4.1477, 2.7423, 3.8388, 3.6860],\n",
       "        [3.1820, 4.1477, 2.7423, 3.8388, 3.6860]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(a, torch.rand([5,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 7., 7.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, a), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6776, 0.3710, 0.8945, 0.8784],\n",
       "        [0.4639, 0.4442, 0.4395, 0.0650],\n",
       "        [0.8493, 0.2488, 0.9899, 0.1586],\n",
       "        [0.7743, 0.2697, 0.1206, 0.9328],\n",
       "        [0.9514, 0.9723, 0.8638, 0.8053],\n",
       "        [0.4224, 0.0471, 0.0620, 0.1813],\n",
       "        [0.8320, 0.7917, 0.9346, 0.3507]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ReLU()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6776, 0.3710, 0.8945, 0.8784],\n",
       "        [0.4639, 0.4442, 0.4395, 0.0650],\n",
       "        [0.8493, 0.2488, 0.9899, 0.1586],\n",
       "        [0.7743, 0.2697, 0.1206, 0.9328],\n",
       "        [0.9514, 0.9723, 0.8638, 0.8053],\n",
       "        [0.4224, 0.0471, 0.0620, 0.1813],\n",
       "        [0.8320, 0.7917, 0.9346, 0.3507]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids = [0,0,1,1,1,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1415, 0.8152, 1.3340, 0.9433],\n",
       "        [2.5749, 1.4907, 1.9743, 1.8967],\n",
       "        [1.2544, 0.8388, 0.9966, 0.5320]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_add(F.relu(a), torch.tensor(seg_ids), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "|\n",
       "\n",
       ".. image:: https://raw.githubusercontent.com/rusty1s/pytorch_scatter/\n",
       "        master/docs/source/_figures/add.svg?sanitize=true\n",
       "    :align: center\n",
       "    :width: 400px\n",
       "\n",
       "|\n",
       "\n",
       "Sums all values from the :attr:`src` tensor into :attr:`out` at the indices\n",
       "specified in the :attr:`index` tensor along a given axis :attr:`dim`. For\n",
       "each value in :attr:`src`, its output index is specified by its index in\n",
       ":attr:`input` for dimensions outside of :attr:`dim` and by the\n",
       "corresponding value in :attr:`index` for dimension :attr:`dim`. If\n",
       "multiple indices reference the same location, their **contributions add**.\n",
       "\n",
       "Formally, if :attr:`src` and :attr:`index` are n-dimensional tensors with\n",
       "size :math:`(x_0, ..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})` and\n",
       ":attr:`dim` = `i`, then :attr:`out` must be an n-dimensional tensor with\n",
       "size :math:`(x_0, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})`. Moreover, the\n",
       "values of :attr:`index` must be between `0` and `out.size(dim) - 1`.\n",
       "\n",
       "For one-dimensional tensors, the operation computes\n",
       "\n",
       ".. math::\n",
       "    \\mathrm{out}_i = \\mathrm{out}_i + \\sum_j \\mathrm{src}_j\n",
       "\n",
       "where :math:`\\sum_j` is over :math:`j` such that\n",
       ":math:`\\mathrm{index}_j = i`.\n",
       "\n",
       "Args:\n",
       "    src (Tensor): The source tensor.\n",
       "    index (LongTensor): The indices of elements to scatter.\n",
       "    dim (int, optional): The axis along which to index.\n",
       "        (default: :obj:`-1`)\n",
       "    out (Tensor, optional): The destination tensor. (default: :obj:`None`)\n",
       "    dim_size (int, optional): If :attr:`out` is not given, automatically\n",
       "        create output with size :attr:`dim_size` at dimension :attr:`dim`.\n",
       "        If :attr:`dim_size` is not given, a minimal sized output tensor is\n",
       "        returned. (default: :obj:`None`)\n",
       "    fill_value (int, optional): If :attr:`out` is not given, automatically\n",
       "        fill output tensor with :attr:`fill_value`. (default: :obj:`0`)\n",
       "\n",
       ":rtype: :class:`Tensor`\n",
       "\n",
       ".. testsetup::\n",
       "\n",
       "    import torch\n",
       "\n",
       ".. testcode::\n",
       "\n",
       "    from torch_scatter import scatter_add\n",
       "\n",
       "    src = torch.Tensor([[2, 0, 1, 4, 3], [0, 2, 1, 3, 4]])\n",
       "    index = torch.tensor([[4, 5, 4, 2, 3], [0, 0, 2, 2, 1]])\n",
       "    out = src.new_zeros((2, 6))\n",
       "\n",
       "    out = scatter_add(src, index, out=out)\n",
       "\n",
       "    print(out)\n",
       "\n",
       ".. testoutput::\n",
       "\n",
       "   tensor([[0., 0., 4., 3., 3., 0.],\n",
       "           [2., 4., 4., 0., 0., 0.]])\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch_scatter/add.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.index_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4)\n",
      "(3, 3, 3)\n",
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(list(zip(a, a, a))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "zip(iter1 [,iter2 [...]]) --> zip object\n",
       "\n",
       "Return a zip object whose .__next__() method returns a tuple where\n",
       "the i-th element comes from the i-th iterable argument.  The .__next__()\n",
       "method continues until the shortest iterable in the argument sequence\n",
       "is exhausted and then it raises StopIteration.\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
