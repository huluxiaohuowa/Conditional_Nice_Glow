{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distrib_zoo as dz\n",
    "import torch\n",
    "from layers import *\n",
    "from func import *\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = SimpleLinear(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_fn(mlp_func, in_feats, out_feats, chunk_sizes):\n",
    "    def mlp(x, cond):\n",
    "        x_ = mlp_func(torch.cat((x, cond), dim=-1))\n",
    "        mu, var = torch.split(x_, chunk_sizes, -1)\n",
    "        var = F.softplus(var)/math.log(2)\n",
    "        return mu, var\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7437],\n",
       "         [0.3418],\n",
       "         [0.6956],\n",
       "         [0.5973],\n",
       "         [0.4781],\n",
       "         [0.8379],\n",
       "         [0.4216]], grad_fn=<SplitWithSizesBackward>),\n",
       " tensor([[0.8899, 1.2222],\n",
       "         [0.9214, 1.2993],\n",
       "         [0.9226, 1.2301],\n",
       "         [0.8311, 1.3665],\n",
       "         [0.8873, 1.4396],\n",
       "         [0.7287, 1.5651],\n",
       "         [0.7332, 1.7231]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_fn(f, 5, 3, [1,2])(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([7,4])\n",
    "b = torch.rand([7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7437, -0.1589,  0.2875],\n",
       "        [ 0.3418, -0.1120,  0.3792],\n",
       "        [ 0.6956, -0.1104,  0.2970],\n",
       "        [ 0.5973, -0.2496,  0.4564],\n",
       "        [ 0.4781, -0.1629,  0.5379],\n",
       "        [ 0.8379, -0.4199,  0.6725],\n",
       "        [ 0.4216, -0.4120,  0.8335]], grad_fn=<EluBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(torch.cat((a,b), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]), tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a,[2,5],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Splits the tensor into chunks.\n",
       "\n",
       "If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
       "be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
       "the tensor size along the given dimension :attr:`dim` is not divisible by\n",
       ":attr:`split_size`.\n",
       "\n",
       "If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
       "into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
       "to :attr:`split_size_or_sections`.\n",
       "\n",
       "Arguments:\n",
       "    tensor (Tensor): tensor to split.\n",
       "    split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
       "        list of sizes for each chunk\n",
       "    dim (int): dimension along which to split the tensor.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]), tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]), tensor([[1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a, a.size(1) // 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
       "\n",
       "Shape:\n",
       "\n",
       "    - Input: :math:`(N, *, in\\_features)` where `*` means any number of\n",
       "      additional dimensions\n",
       "    - Weight: :math:`(out\\_features, in\\_features)`\n",
       "    - Bias: :math:`(out\\_features)`\n",
       "    - Output: :math:`(N, *, out\\_features)`\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?F.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dz.InvLinear(7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023],\n",
       "        [-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023],\n",
       "        [-0.5545, -1.5532, -0.2023,  1.3605,  0.9206, -0.9471,  0.8023]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1820, 4.1477, 2.7423, 3.8388, 3.6860],\n",
       "        [3.1820, 4.1477, 2.7423, 3.8388, 3.6860],\n",
       "        [3.1820, 4.1477, 2.7423, 3.8388, 3.6860]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(a, torch.rand([5,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 7., 7.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, a), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6776, 0.3710, 0.8945, 0.8784],\n",
       "        [0.4639, 0.4442, 0.4395, 0.0650],\n",
       "        [0.8493, 0.2488, 0.9899, 0.1586],\n",
       "        [0.7743, 0.2697, 0.1206, 0.9328],\n",
       "        [0.9514, 0.9723, 0.8638, 0.8053],\n",
       "        [0.4224, 0.0471, 0.0620, 0.1813],\n",
       "        [0.8320, 0.7917, 0.9346, 0.3507]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ReLU()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6776, 0.3710, 0.8945, 0.8784],\n",
       "        [0.4639, 0.4442, 0.4395, 0.0650],\n",
       "        [0.8493, 0.2488, 0.9899, 0.1586],\n",
       "        [0.7743, 0.2697, 0.1206, 0.9328],\n",
       "        [0.9514, 0.9723, 0.8638, 0.8053],\n",
       "        [0.4224, 0.0471, 0.0620, 0.1813],\n",
       "        [0.8320, 0.7917, 0.9346, 0.3507]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids = [0,0,1,1,1,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1415, 0.8152, 1.3340, 0.9433],\n",
       "        [2.5749, 1.4907, 1.9743, 1.8967],\n",
       "        [1.2544, 0.8388, 0.9966, 0.5320]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_add(F.relu(a), torch.tensor(seg_ids), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "|\n",
       "\n",
       ".. image:: https://raw.githubusercontent.com/rusty1s/pytorch_scatter/\n",
       "        master/docs/source/_figures/add.svg?sanitize=true\n",
       "    :align: center\n",
       "    :width: 400px\n",
       "\n",
       "|\n",
       "\n",
       "Sums all values from the :attr:`src` tensor into :attr:`out` at the indices\n",
       "specified in the :attr:`index` tensor along a given axis :attr:`dim`. For\n",
       "each value in :attr:`src`, its output index is specified by its index in\n",
       ":attr:`input` for dimensions outside of :attr:`dim` and by the\n",
       "corresponding value in :attr:`index` for dimension :attr:`dim`. If\n",
       "multiple indices reference the same location, their **contributions add**.\n",
       "\n",
       "Formally, if :attr:`src` and :attr:`index` are n-dimensional tensors with\n",
       "size :math:`(x_0, ..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})` and\n",
       ":attr:`dim` = `i`, then :attr:`out` must be an n-dimensional tensor with\n",
       "size :math:`(x_0, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})`. Moreover, the\n",
       "values of :attr:`index` must be between `0` and `out.size(dim) - 1`.\n",
       "\n",
       "For one-dimensional tensors, the operation computes\n",
       "\n",
       ".. math::\n",
       "    \\mathrm{out}_i = \\mathrm{out}_i + \\sum_j \\mathrm{src}_j\n",
       "\n",
       "where :math:`\\sum_j` is over :math:`j` such that\n",
       ":math:`\\mathrm{index}_j = i`.\n",
       "\n",
       "Args:\n",
       "    src (Tensor): The source tensor.\n",
       "    index (LongTensor): The indices of elements to scatter.\n",
       "    dim (int, optional): The axis along which to index.\n",
       "        (default: :obj:`-1`)\n",
       "    out (Tensor, optional): The destination tensor. (default: :obj:`None`)\n",
       "    dim_size (int, optional): If :attr:`out` is not given, automatically\n",
       "        create output with size :attr:`dim_size` at dimension :attr:`dim`.\n",
       "        If :attr:`dim_size` is not given, a minimal sized output tensor is\n",
       "        returned. (default: :obj:`None`)\n",
       "    fill_value (int, optional): If :attr:`out` is not given, automatically\n",
       "        fill output tensor with :attr:`fill_value`. (default: :obj:`0`)\n",
       "\n",
       ":rtype: :class:`Tensor`\n",
       "\n",
       ".. testsetup::\n",
       "\n",
       "    import torch\n",
       "\n",
       ".. testcode::\n",
       "\n",
       "    from torch_scatter import scatter_add\n",
       "\n",
       "    src = torch.Tensor([[2, 0, 1, 4, 3], [0, 2, 1, 3, 4]])\n",
       "    index = torch.tensor([[4, 5, 4, 2, 3], [0, 0, 2, 2, 1]])\n",
       "    out = src.new_zeros((2, 6))\n",
       "\n",
       "    out = scatter_add(src, index, out=out)\n",
       "\n",
       "    print(out)\n",
       "\n",
       ".. testoutput::\n",
       "\n",
       "   tensor([[0., 0., 4., 3., 3., 0.],\n",
       "           [2., 4., 4., 0., 0., 0.]])\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/torch_scatter/add.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.index_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len([2,4])).repeat([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
